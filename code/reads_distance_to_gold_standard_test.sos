#!/usr/bin/env sos-runner
#fileformat=SOS1.0

# This script will generate files that will be used to calculate the distribution of reads 5' end with gold standard 
# Example code to run


from glob import glob
from subprocess import check_output

[random_sample_regions: alias = 'random_regions']
## random sample 10,000 sites for each plus strand minus strand, each bed region will be given a name
rawfiles = sorted(glob('../data/published_site/*extend.bed'))
input: rawfiles, pattern = '../data/published_site/{name}.extend.bed', group_by = 'single'
output: pattern = '../data/published_site/{_name}.extend_sub_10000.bed'
run:	concurrent = True
shuf -n 10000 ${_input} | awk {'print $1"\t"$2"\t"$3"\t"NR"\t"$4'} > ${_output}


[get_coverage_1: alias = 'prime5_bed']
# generate bed files with only 5prime ends for both plus reads and minus reads, 
#the output sequence matters to match plus strand read with minus 
#strand methylation regions.
bam_files = sorted(glob('../data/Data/*.adaptor_removed.bam'))
input: bam_files, pattern = '../data/Data/{name}.bam', group_by	= "single"
output: pattern = ['../data/Data/{_name}.plus.sorted.5prime.bed','../data/Data/{_name}.minus.sorted.5prime.bed']
run:	concurrent = True
samtools view -b -F 20 -o ../data/Data/${_name}.plus.bam ${_input} 
samtools view -b -f 16 -o ../data/Data/${_name}.minus.bam ${_input} 
samtools sort ../data/Data/${_name}.plus.bam ../data/Data/${_name}.plus.sorted
samtools sort ../data/Data/${_name}.minus.bam ../data/Data/${_name}.minus.sorted
# for plus strand reads, only keep the 5' position
bedtools bamtobed -i ../data/Data/${_name}.plus.sorted.bam | awk {'print $1"\t"$2"\t"$2+1"\t"$4"\t"$5"\t"$6'} \
> ../data/Data/${_name}.plus.sorted.5prime.bed
# for minus strand reads,only keep 5' position
bedtools bamtobed -i ../data/Data/${_name}.minus.sorted.bam | awk {'print $1"\t"$3-1"\t"$3"\t"$4"\t"$5"\t"$6'} \
> ../data/Data/${_name}.minus.sorted.5prime.bed


[get_coverage_2]
# calculate coverage
#need to consider how to pair the regon files with bam files approriately, now there is only one pair of regions, but multiple pairs of
#bam files

regions = random_regions.output
prime5_bed_files = prime5_bed.output
input: regions, paired_with = ['prime5_bed_files'], group_by = 'single', pattern = '../data/published_site/{name}.extend_sub_10000.bed'
output: pattern = '../data/published_site/{_name}.sub_10000.extend.genomecov'
run:	concurrent = True
bedtools coverage -a ${_prime5_bed_files} -b ${_input} -d > ${_output}




[regions_with_at_least_one_coverage_1: alias = 'one_coverage_regions']
## use all regions that have at least one read coverage
rawfiles = sorted(glob('../data/published_site/*extend.bed'))
reads_bed_files = prime5_bed.output
input: rawfiles, paired_with = ['reads_bed_files'], group_by = 'single', pattern = '../data/published_site/{name}.extend.bed'
output: pattern = '../data/published_site/{_name}.with_1_coverage.bed'
run:	concurrent = True
awk {'print $1"\t"$2"\t"$3"\t"NR'} ${_input} > ../data/published_site/${_name}_with_index.bed
bedtools intersect -wa -a ../data/published_site/${_name}_with_index.bed -b ${_reads_bed_files} | sort | uniq > ${_output}

[regions_with_at_least_one_coverage_2]
prime5_bed_files = prime5_bed.output
input: paired_with = ['prime5_bed_files'], group_by = 'single', pattern = '../data/published_site/{name}.with_1_coverage.bed'
output: pattern = '../data/published_site/{_name}.with_1_coverage.bedGraph'
run:	concurrent = True
bedtools coverage -a ${_prime5_bed_files} -b ${_input} -d > ${_output}

[regions_with_at_least_one_coverage_3]
#write average per-base coverage
input: pattern = '../data/published_site/{name}.with_1_coverage.bedGraph', group_by = 'single'
output: pattern = '../data/published_site/{_name}.with_1_coverage.ave.perbase'
run: 	concurrent = True
rm -f ../data/published_site/{_name}.with_1_coverage.ave.perbase
for i in {1..41} /
do awk -v i="$i" '$5 == i' ${_input} | awk '{print $6}'|paste -s -d+ | bc >> ${_output}
done



[nonoverlapping_regions: alias = 'non-overlapping_regions']
## only consider nonoverlapping regions
rawfiles = sorted(glob('../data/published_site/*extend.bed'))
input: rawfiles, pattern = '../data/published_site/{name}.extend.bed', group_by = 'single'
output: pattern = '../data/published_site/{_name}.extend_nonooverlapping.bed'
run:	concurrent = True
bedtools merge -i <(awk {'print $1"\t"$2"\t"$3'} ${_input} | sort -k1,1 -k2,2n) | awk {'print $1"\t"$2"\t"$3"\t"$3-$2'} | awk '$4<=41' > ${_output}


[non_overlapping_regions_with_at_least_one_coverage_1: alias = 'nonover_one_coverage_regions']
## use all regions that have at least one read coverage
rawfiles = sorted(glob('../data/published_site/*extend_nonooverlapping.bed'))
reads_bed_files = prime5_bed.output
input: rawfiles, paired_with = ['reads_bed_files'], group_by = 'single', pattern = '../data/published_site/{name}.extend_nonooverlapping.bed'
output: pattern = '../data/published_site/{_name}.nonoverlappig_with_1_coverage.bed'
run:	concurrent = True
awk {'print $1"\t"$2"\t"$3"\t"NR'} ${_input} > ../data/published_site/${_name}_nonoverlapping_with_index.bed
bedtools intersect -wa -a ../data/published_site/${_name}_nonoverlapping_with_index.bed -b ${_reads_bed_files} | sort | uniq > ${_output}

[non_overlapping_regions_with_at_least_one_coverage_2]
prime5_bed_files = prime5_bed.output
input: paired_with = ['prime5_bed_files'], group_by = 'single', pattern = '../data/published_site/{name}.nonoverlappig_with_1_coverage.bed'
output: pattern = '../data/published_site/{_name}.nonoverlapping_with_1_coverage.bedGraph'
run:	concurrent = True
bedtools coverage -a ${_prime5_bed_files} -b ${_input} -d > ${_output}

[non_overlapping_regions_with_at_least_one_coverage_3]
#write average per-base coverage
input: pattern = '../data/published_site/{name}.nonoverlapping_with_1_coverage.bedGraph', group_by = 'single'
output: pattern = '../data/published_site/{_name}.nonoverlapping_with_1_coverage.ave.perbase'
run: 	concurrent = True
rm -f ../data/published_site/{_name}.nonoverlapping_with_1_coverage.ave.perbase
for i in {1..41} /
do awk -v i="$i" '$5 == i' ${_input} | awk '{print $6}'|paste -s -d+ | bc >> ${_output}
done

[draw_plot_by_rmarkdown]
# generate rmarkdown file showing the distribution of the 5'reads across all sites
Rmarkdown: output_file='report.html'
read in one of the output files from the previous step
```{r}
data1 = read.delim(${input!r}, header = FALSE, sep = "\t", stringsAsFactors = FALSE)
plot(data1[,1])
```


[default]
#sos_run('random_sample_regions+get_coverage')
sos_run('random_sample_regions+get_coverage+regions_with_at_least_one_coverage+nonoverlapping_regions+non_overlapping_regions_with_at_least_one_coverage')
#sos_run('nonoverlapping_regions')